{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "fByj5NUe0__I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bMaGhqYPRZB8",
        "outputId": "7c1b9189-7c39-4fa5-f085-ea765c1fe3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.35)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langchain-huggingface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed langchain-huggingface-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import math\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "import json"
      ],
      "metadata": {
        "id": "5CG9zVN6SFu1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key=userdata.get(\"HF_API\")"
      ],
      "metadata": {
        "id": "SDeu2Dl8SHul"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the JSON file with multiple objects (line-delimited JSON)\n",
        "rgb_response_data_without_doc = pd.read_json('/content/en_fact.json', lines=True)\n",
        "rgb_response_data_doc = pd.read_json('/content/en_fact.json', lines=True)"
      ],
      "metadata": {
        "id": "I_qbsQYkSSDn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Execution for LLM without Documents"
      ],
      "metadata": {
        "id": "0viq4DXV0s0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processdata(instance):\n",
        "    docs = []\n",
        "    positive = instance['positive_wrong']\n",
        "    # negative = instance['negative']\n",
        "\n",
        "    docs = positive  # + negative\n",
        "\n",
        "    random.shuffle(docs)\n",
        "\n",
        "    return docs"
      ],
      "metadata": {
        "id": "B98h5nT0WQwq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_content = \"You are an accurate and reliable AI assistant that can answer questions.Aswer the question \"\n"
      ],
      "metadata": {
        "id": "qMUvM9P6XJ3V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response_prompt_wihtout_doc():\n",
        "    retrieval_prompt= sys_content +\" the Question is :\\n{QUERY}\"\n",
        "    retrieval_prompt_template = PromptTemplate.from_template(retrieval_prompt)\n",
        "    return retrieval_prompt_template"
      ],
      "metadata": {
        "id": "alELMSJ-8cM1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hugging_face_llm_response_withoutDocs(question,eval_model,temp):\n",
        "\n",
        "     # Set up the LLM endpoint\n",
        "    llm_retrieval = HuggingFaceEndpoint(\n",
        "        repo_id=eval_model,\n",
        "        temperature=temp,\n",
        "        huggingfacehub_api_token=api_key,\n",
        "    )\n",
        "\n",
        "    # Combine the retrieval template and the LLM\n",
        "    llm_retrieval_chain = response_prompt_wihtout_doc() | llm_retrieval\n",
        "\n",
        "    # Prepare input for the chain\n",
        "    input_retrieval = {\n",
        "\n",
        "        \"QUERY\": question\n",
        "    }\n",
        "\n",
        "    # Invoke the chain to generate a response\n",
        "    try:\n",
        "        llm_response = llm_retrieval_chain.invoke(input_retrieval)\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking LLM retrieval chain: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "IY1DaqtSEYI7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkanswer(prediction, ground_truth):\n",
        "    prediction = prediction.lower()\n",
        "    if type(ground_truth) is not list:\n",
        "        ground_truth = [ground_truth]\n",
        "    labels = []\n",
        "    for instance in ground_truth:\n",
        "        flag = True\n",
        "        if type(instance)  == list:\n",
        "            flag = False\n",
        "            instance = [i.lower() for i in instance]\n",
        "            for i in instance:\n",
        "                if i in prediction:\n",
        "                    flag = True\n",
        "                    break\n",
        "        else:\n",
        "            instance = instance.lower()\n",
        "            if instance not in prediction:\n",
        "                flag = False\n",
        "        labels.append(int(flag))\n",
        "    return labels"
      ],
      "metadata": {
        "id": "MRy9gVQkXbWF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "def get_hugging_face_llm_response_new(documents, question, eval_model, temp, api_key):\n",
        "    # Set up the Inference Client\n",
        "    client = InferenceClient(model=eval_model, token=api_key)\n",
        "\n",
        "    # Prepare input prompt\n",
        "    input_text = f\"{sys_content} Context: {documents}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "\n",
        "    try:\n",
        "        # Generate response using `text_generation` method\n",
        "        response = client.text_generation(input_text, temperature=temp, max_new_tokens=1024)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking LLM retrieval chain: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "6qyF5Fp5G1ah"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compare_val_answer(llm_answer,ground_truth):\n",
        "    if 'insufficient information' in llm_answer:\n",
        "        labels = [-1]\n",
        "\n",
        "    else:\n",
        "        labels = checkanswer(llm_answer, ground_truth)\n",
        "\n",
        "    factlabel = 0\n",
        "\n",
        "    if 'factual errors' in llm_answer:\n",
        "        factlabel = 1\n",
        "\n",
        "    return labels,llm_answer,factlabel"
      ],
      "metadata": {
        "id": "cnGMtne-XXyp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_response_data_without_doc['answer_without_doc'] = None\n",
        "rgb_response_data_without_doc['label_without_doc'] = None"
      ],
      "metadata": {
        "id": "6WBErmkTFLLv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json(file_name, count, llm_response_for_query, question, labels,ground_truth, fact_level):\n",
        "    newinstance = {\n",
        "        \"count\": count,\n",
        "        \"question\": question,\n",
        "        \"answer\": llm_response_for_query,\n",
        "        \"groud_truth\": ground_truth,\n",
        "        \"label\": labels,\n",
        "        \"fact_level\": fact_level\n",
        "    }\n",
        "\n",
        "    # Append to file\n",
        "    with open(file_name, 'a', encoding='utf-8') as f:\n",
        "        f.write(json.dumps(newinstance, ensure_ascii=False) + '\\n')\n",
        " # Return the JSON object if needed\n"
      ],
      "metadata": {
        "id": "0u-K1o6LZCr0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "def get_hugging_face_llm_response_new_without_doc(question, eval_model, temp, api_key):\n",
        "    # Set up the Inference Client\n",
        "    client = InferenceClient(model=eval_model, token=api_key)\n",
        "\n",
        "    # Prepare input prompt\n",
        "    input_text = f\"{sys_content} Question: {question}\"\n",
        "\n",
        "    try:\n",
        "        # Generate response using `text_generation` method\n",
        "        response = client.text_generation(input_text, temperature=temp, max_new_tokens=1024)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking LLM retrieval chain: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "hruVm4C1Vooo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execution = 0\n",
        "insufficient_info = 0 # Initialize the  counter\n",
        "fact_error_exe=0\n",
        "\n",
        "results = []  # List to store results for calculating the ratio later\n",
        "response_model=\"google/gemma-2-27b-it\"  #llama-3.3-70b-versatile,mixtral-8x7b-32768,Qwen/QwQ-32B-Preview,mistralai/Mistral-7B-Instruct-v0.3\n",
        "temp = 0.5\n",
        "for index, row in rgb_response_data_without_doc.iterrows():\n",
        "    # Generate samples based on positive, negative data\n",
        "    print(index)\n",
        "\n",
        "    # docs = processdata(row)\n",
        "    #documents, question, eval_model, temp, api_key\n",
        "    llm_answer = get_hugging_face_llm_response_new_without_doc( row[\"query\"], response_model, temp,api_key)\n",
        "\n",
        "    if llm_answer is not None:\n",
        "        # Compare the LLM answer with the ground truth\n",
        "        labels, llm_answer, factlabel = get_compare_val_answer(llm_answer, row[\"answer\"])\n",
        "        rgb_response_data_without_doc.at[index,'answer_without_doc'] = llm_answer\n",
        "        result = 0 if 0 in labels else 1 if 1 in labels else None\n",
        "        rgb_response_data_without_doc.at[index, 'label_without_doc'] = result\n",
        "        create_json(\"llm_response_contra_wihtout_doc_72.json\",index,llm_answer,row[\"query\"],labels,row[\"answer\"],factlabel)\n",
        "\n",
        "        # Implement the tt logic\n",
        "        if -1 in labels:\n",
        "            insufficient_info += 1\n",
        "        if 0 in labels or 1 in labels:\n",
        "            execution += 1\n",
        "        if factlabel == 1:\n",
        "            fact_error_exe += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bic-buIHSdRm",
        "outputId": "aba5f77e-7a93-4689-f4f3-adc8e66b5644"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where label_without_doc == 1\n",
        "filtered_df = rgb_response_data_without_doc[rgb_response_data_without_doc['label_without_doc'] == 1]\n",
        "\n",
        "# Compute proportion of label_without_doc == 1\n",
        "accuracy = len(filtered_df) / len(rgb_response_data_without_doc)\n",
        "print(\"Proportion of label_without_doc = 1:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32E2PopWlCE0",
        "outputId": "3c1eb3ca-2c2e-432b-ecc8-b987a76b6d3d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of label_without_doc = 1: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution for LLM with Positive_Wrong Documents"
      ],
      "metadata": {
        "id": "g2eXunPY0etW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_response_data_without_doc.sample(5)"
      ],
      "metadata": {
        "id": "v-RqlARSNIlf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e1eb25d-4cba-4828-9a64-a1c3e598ca15",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                              query            answer  \\\n",
              "0    0                           Super Bowl 2021 location    Tampa, Florida   \n",
              "1    1  Which country won the most medals at the 2018 ...            Norway   \n",
              "2    2                            Who acquired Instagram?          Facebook   \n",
              "3    3                             Who acquired WhatsApp?          Facebook   \n",
              "4    4     Who won the women's singles Wimbledon in 2019?      Simona Halep   \n",
              "..  ..                                                ...               ...   \n",
              "95  95                   Who is the CEO of Apple in 2021?          Tim Cook   \n",
              "96  96       Who won the Masters golf tournament in 2021?  Hideki Matsuyama   \n",
              "97  97  Who won the British Open golf tournament in 2020?       Shane Lowry   \n",
              "98  98       which city hosted the olympic games in 2008?           Beijing   \n",
              "99  99       which city hosted the olympic games in 2004?            Athens   \n",
              "\n",
              "           fakeanswer                                     positive_wrong  \\\n",
              "0   Glendale, Arizona  [The game was played on February 7, 2021, at R...   \n",
              "1                U.S.  [U.S. set the record for most total medals at ...   \n",
              "2               Apple  [Jul 27, 2022 ... When Apple made a bid to buy...   \n",
              "3               Apple  [Apple purchased WhatsApp in 2014. · Apple's b...   \n",
              "4    Angelique Kerber  [Angelique Kerber defeated Serena Williams in ...   \n",
              "..                ...                                                ...   \n",
              "95         Steve Jobs  [Steve Jobs is Apple's CEO and a member of App...   \n",
              "96        Shane Lowry  [Apr 12, 2021 ... Shane Lowry made history for...   \n",
              "97   Hideki Matsuyama  [Jul 13, 2021 ... The 2020 British Open was ca...   \n",
              "98             London  [Under the direction of Liu Qi, London was ele...   \n",
              "99           New York  [New York became one of only four cities at th...   \n",
              "\n",
              "                                             positive  \\\n",
              "0   [The game was played on February 7, 2021, at R...   \n",
              "1   [Norway set the record for most total medals a...   \n",
              "2   [Jul 27, 2022 ... When Facebook made a bid to ...   \n",
              "3   [Facebook purchased WhatsApp in 2014. · Facebo...   \n",
              "4   [Simona Halep defeated Serena Williams in the ...   \n",
              "..                                                ...   \n",
              "95  [Tim Cook is Apple's CEO and a member of Apple...   \n",
              "96  [Apr 12, 2021 ... Hideki Matsuyama made histor...   \n",
              "97  [Jul 13, 2021 ... The 2020 British Open was ca...   \n",
              "98  [Under the direction of Liu Qi, Beijing was el...   \n",
              "99  [Athens became one of only four cities at the ...   \n",
              "\n",
              "                                             negative  \\\n",
              "0   [Official Super Bowl LVIII Ticket Packages Now...   \n",
              "1   [PyeongChang's vision for the 2018 Games was t...   \n",
              "2   [The company remained independent up until it ...   \n",
              "3   [Jun 6, 2023 ... WhatsApp was founded in 2009 ...   \n",
              "4   [Carlos Alcaraz wins the clinching point in th...   \n",
              "..                                                ...   \n",
              "95  [Apple chief executive (2011–present). After J...   \n",
              "96  [Official home of The 2023 Masters at Augusta ...   \n",
              "97  [The championship was won by Collin Morikawa w...   \n",
              "98  [Dec 14, 2021 ... The costs of hosting the Oly...   \n",
              "99  [Dec 14, 2021 ... The costs of hosting the Oly...   \n",
              "\n",
              "                                   answer_without_doc label_without_doc  \n",
              "0   \\n\\nAnswer: Super Bowl LV was played at Raymon...                 1  \n",
              "1   \\n\\nAnswer: **Norway** won the most medals at ...                 1  \n",
              "2   \\n\\nAnswer: Instagram was acquired by **Facebo...                 1  \n",
              "3   \\n\\nAnswer: WhatsApp was acquired by **Faceboo...                 1  \n",
              "4                       \\n\\nAnswer: Simona Halep \\n\\n                 1  \n",
              "..                                                ...               ...  \n",
              "95  \\n\\nAnswer: Tim Cook was the CEO of Apple in 2...                 1  \n",
              "96  \\n\\nAnswer: **Hideki Matsuyama** won the Maste...                 1  \n",
              "97  \\n\\nAnswer: **Shane Lowry** won the British Op...                 1  \n",
              "98                             \\n\\nAnswer: Beijing \\n                 1  \n",
              "99                    \\n\\nAnswer: Athens, Greece \\n\\n                 1  \n",
              "\n",
              "[100 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77fcf7af-c0d5-4ab2-ab1b-0797c342d168\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>answer</th>\n",
              "      <th>fakeanswer</th>\n",
              "      <th>positive_wrong</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>answer_without_doc</th>\n",
              "      <th>label_without_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Super Bowl 2021 location</td>\n",
              "      <td>Tampa, Florida</td>\n",
              "      <td>Glendale, Arizona</td>\n",
              "      <td>[The game was played on February 7, 2021, at R...</td>\n",
              "      <td>[The game was played on February 7, 2021, at R...</td>\n",
              "      <td>[Official Super Bowl LVIII Ticket Packages Now...</td>\n",
              "      <td>\\n\\nAnswer: Super Bowl LV was played at Raymon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Which country won the most medals at the 2018 ...</td>\n",
              "      <td>Norway</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>[U.S. set the record for most total medals at ...</td>\n",
              "      <td>[Norway set the record for most total medals a...</td>\n",
              "      <td>[PyeongChang's vision for the 2018 Games was t...</td>\n",
              "      <td>\\n\\nAnswer: **Norway** won the most medals at ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Who acquired Instagram?</td>\n",
              "      <td>Facebook</td>\n",
              "      <td>Apple</td>\n",
              "      <td>[Jul 27, 2022 ... When Apple made a bid to buy...</td>\n",
              "      <td>[Jul 27, 2022 ... When Facebook made a bid to ...</td>\n",
              "      <td>[The company remained independent up until it ...</td>\n",
              "      <td>\\n\\nAnswer: Instagram was acquired by **Facebo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Who acquired WhatsApp?</td>\n",
              "      <td>Facebook</td>\n",
              "      <td>Apple</td>\n",
              "      <td>[Apple purchased WhatsApp in 2014. · Apple's b...</td>\n",
              "      <td>[Facebook purchased WhatsApp in 2014. · Facebo...</td>\n",
              "      <td>[Jun 6, 2023 ... WhatsApp was founded in 2009 ...</td>\n",
              "      <td>\\n\\nAnswer: WhatsApp was acquired by **Faceboo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Who won the women's singles Wimbledon in 2019?</td>\n",
              "      <td>Simona Halep</td>\n",
              "      <td>Angelique Kerber</td>\n",
              "      <td>[Angelique Kerber defeated Serena Williams in ...</td>\n",
              "      <td>[Simona Halep defeated Serena Williams in the ...</td>\n",
              "      <td>[Carlos Alcaraz wins the clinching point in th...</td>\n",
              "      <td>\\n\\nAnswer: Simona Halep \\n\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Who is the CEO of Apple in 2021?</td>\n",
              "      <td>Tim Cook</td>\n",
              "      <td>Steve Jobs</td>\n",
              "      <td>[Steve Jobs is Apple's CEO and a member of App...</td>\n",
              "      <td>[Tim Cook is Apple's CEO and a member of Apple...</td>\n",
              "      <td>[Apple chief executive (2011–present). After J...</td>\n",
              "      <td>\\n\\nAnswer: Tim Cook was the CEO of Apple in 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Who won the Masters golf tournament in 2021?</td>\n",
              "      <td>Hideki Matsuyama</td>\n",
              "      <td>Shane Lowry</td>\n",
              "      <td>[Apr 12, 2021 ... Shane Lowry made history for...</td>\n",
              "      <td>[Apr 12, 2021 ... Hideki Matsuyama made histor...</td>\n",
              "      <td>[Official home of The 2023 Masters at Augusta ...</td>\n",
              "      <td>\\n\\nAnswer: **Hideki Matsuyama** won the Maste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>Who won the British Open golf tournament in 2020?</td>\n",
              "      <td>Shane Lowry</td>\n",
              "      <td>Hideki Matsuyama</td>\n",
              "      <td>[Jul 13, 2021 ... The 2020 British Open was ca...</td>\n",
              "      <td>[Jul 13, 2021 ... The 2020 British Open was ca...</td>\n",
              "      <td>[The championship was won by Collin Morikawa w...</td>\n",
              "      <td>\\n\\nAnswer: **Shane Lowry** won the British Op...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>which city hosted the olympic games in 2008?</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>London</td>\n",
              "      <td>[Under the direction of Liu Qi, London was ele...</td>\n",
              "      <td>[Under the direction of Liu Qi, Beijing was el...</td>\n",
              "      <td>[Dec 14, 2021 ... The costs of hosting the Oly...</td>\n",
              "      <td>\\n\\nAnswer: Beijing \\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>which city hosted the olympic games in 2004?</td>\n",
              "      <td>Athens</td>\n",
              "      <td>New York</td>\n",
              "      <td>[New York became one of only four cities at th...</td>\n",
              "      <td>[Athens became one of only four cities at the ...</td>\n",
              "      <td>[Dec 14, 2021 ... The costs of hosting the Oly...</td>\n",
              "      <td>\\n\\nAnswer: Athens, Greece \\n\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77fcf7af-c0d5-4ab2-ab1b-0797c342d168')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77fcf7af-c0d5-4ab2-ab1b-0797c342d168 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77fcf7af-c0d5-4ab2-ab1b-0797c342d168');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-763b32bf-6907-4e32-a0ee-2973174f0f90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-763b32bf-6907-4e32-a0ee-2973174f0f90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-763b32bf-6907-4e32-a0ee-2973174f0f90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09188495-9439-43f7-ba6f-ba4580d32c75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rgb_response_data_without_doc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09188495-9439-43f7-ba6f-ba4580d32c75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rgb_response_data_without_doc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rgb_response_data_without_doc",
              "summary": "{\n  \"name\": \"rgb_response_data_without_doc\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Who is the director of \\\"The Godfather\\\"?\",\n          \"What is the release date of Cyberpunk 2077?\",\n          \"When will the first season of The Blacklist premiere?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fakeanswer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"Gal Gadot\",\n          \"Novak Djokovic\",\n          \"Shane Lowry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_wrong\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_without_doc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"\\n\\nAnswer: **Soul** won the Oscar for Best Animated Film in 2021. \\n\\n\",\n          \"\\n\\nThe iPhone 11 was released on **September 20, 2019**. \\n\\n\",\n          \"\\n\\nAnswer: **Hideki Matsuyama** won the Masters golf tournament in 2021. \\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_without_doc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys_content_with_doc = \"You are an accurate and reliable AI assistant that can answer questions with the help of external documents. Please note that external documents may contain noisy or factually incorrect information. If the information in the document contains the correct answer, you will give an accurate answer. If the information in the document does not contain the answer, you will generate ’I can not answer the question because of the insufficient information in documents.‘. If there are inconsistencies with the facts in some of the documents, please generate the response 'There are factual errors in the provided documents.' and provide the correct answer.\""
      ],
      "metadata": {
        "id": "rWSXi3BMNIhB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response_prompt():\n",
        "    retrieval_prompt= sys_content_with_doc +\"Document:\\n{documents} \\n\\nQuestion:\\n{question}\"\n",
        "    retrieval_prompt_template = PromptTemplate.from_template(retrieval_prompt)\n",
        "    return retrieval_prompt_template"
      ],
      "metadata": {
        "id": "ExlvhBZfMn9D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hugging_face_llm_response(documents,question,eval_model,temp):\n",
        "\n",
        "     # Set up the LLM endpoint\n",
        "    llm_retrieval = HuggingFaceEndpoint(\n",
        "        repo_id=eval_model,\n",
        "        temperature=temp,\n",
        "        huggingfacehub_api_token=api_key,\n",
        "    )\n",
        "\n",
        "    # Combine the retrieval template and the LLM\n",
        "    llm_retrieval_chain = response_prompt() | llm_retrieval\n",
        "\n",
        "    # Prepare input for the chain\n",
        "    input_retrieval = {\n",
        "        \"documents\": documents,\n",
        "        \"question\": question\n",
        "    }\n",
        "\n",
        "    # Invoke the chain to generate a response\n",
        "    try:\n",
        "        llm_response = llm_retrieval_chain.invoke(input_retrieval)\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking LLM retrieval chain: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "gtvv9CZxW_WJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_response_data_doc['label_with_doc'] = None\n",
        "rgb_response_data_doc['fact_level'] = None\n",
        "rgb_response_data_doc['answer_with_doc'] = None"
      ],
      "metadata": {
        "id": "k7ODfzXjOXey"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execution_1 = 0\n",
        "insufficient_info_1 = 0 # Initialize the  counter\n",
        "fact_error_exe_1=0\n",
        "\n",
        "results = []  # List to store results for calculating the ratio later\n",
        "response_model=\"Qwen/QwQ-32B-Preview\"  #llama-3.3-70b-versatile,mixtral-8x7b-32768,Qwen/QwQ-32B-Preview,mistralai/Mistral-7B-Instruct-v0.3\n",
        "temp = 0.7\n",
        "for index, row in rgb_response_data_without_doc.iterrows():\n",
        "    # Generate samples based on positive, negative data\n",
        "    print(index)\n",
        "\n",
        "    # docs = processdata(row)\n",
        "\n",
        "    llm_answer = get_hugging_face_llm_response_new(row['positive_wrong'] ,row[\"query\"], response_model,temp,api_key)\n",
        "\n",
        "    if llm_answer is not None:\n",
        "        # Compare the LLM answer with the ground truth\n",
        "        labels, llm_answer, factlabel = get_compare_val_answer(llm_answer, row[\"answer\"])\n",
        "        rgb_response_data_without_doc.at[index, 'answer_with_doc'] = llm_answer\n",
        "        rgb_response_data_without_doc.at[index, 'label_with_doc'] = labels\n",
        "        rgb_response_data_without_doc.at[index, 'fact_level'] = factlabel\n",
        "\n",
        "        create_json(\"llm_response_withdoc_32.json\",index,llm_answer,row[\"query\"],labels,row[\"answer\"],factlabel)\n",
        "\n",
        "        # Implement the tt logic\n",
        "        if -1 in labels:\n",
        "            insufficient_info_1 += 1\n",
        "        if 0 in labels or 1 in labels:\n",
        "            execution_1 += 1\n",
        "        if factlabel == 1:\n",
        "            fact_error_exe_1 += 1\n",
        "\n",
        "# # print(\"Acccuracy with Doc\") :  #rgb_response_data_without_doc['label_with_doc'].value_counts() = 1 the count of 1\n",
        "# print(f\"ED with Doc is {fact_error_exe_1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxDlbtB0MdR8",
        "outputId": "c768584c-6441-4e54-a4a7-15c5d5cc44ae",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ED with Doc is {fact_error_exe_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjKmWdeFOTcK",
        "outputId": "8f65958f-04e5-46db-b5eb-d3181ced3df7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ED with Doc is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_response_data_without_doc['label_with_doc'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "J1bzBxBCqPQI",
        "outputId": "af7078e6-2487-4f25-9bea-15409637bb3c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label_with_doc\n",
              "0.0    77\n",
              "1.0    23\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_with_doc</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_response_data_without_doc['fact_level'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "p7LNyBqYHHa_",
        "outputId": "74785c4a-28c1-46d7-b8b6-fc630e6c83d6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fact_level\n",
              "0.0    100\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fact_level</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter where fact_level == 1 and other_column == 1\n",
        "filtered_df = rgb_response_data_without_doc[(rgb_response_data_without_doc[\"fact_level\"] == 1) & (rgb_response_data_without_doc[\"label_with_doc\"] == 1)]\n",
        "print(\"Correction rate :\",filtered_df.shape[0]/fact_error_exe_1)"
      ],
      "metadata": {
        "id": "ZSSvYq1xHHY8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "2915c664-dc15-4d94-fa91-98787a733f3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-38cbd3f8f4cd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter where fact_level == 1 and other_column == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_response_data_without_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_response_data_without_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fact_level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrgb_response_data_without_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_with_doc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correction rate :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfact_error_exe_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "895xa7MEdzBa",
        "outputId": "f049c219-fc3d-492c-d390-4cc7fb393f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_tKXEq9G1X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hRtArMeG1VR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}